'use client';

import { Send, FileText, X, ArrowUp, Loader2 } from 'lucide-react';
import { useState, useRef, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import Textarea from 'react-textarea-autosize';
import FileUpload from '@/components/FileUpload';
import { Markdown } from '@/components/Markdown';
import CanvasBackground from '@/components/canvas-background';

export default function ChatPage() {
  const [inputText, setInputText] = useState('');
  const [uploadedFile, setUploadedFile] = useState<File | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [messages, setMessages] = useState<
    Array<{
      id: number;
      type: string;
      content: string;
      sender: 'user' | 'ai';
      timestamp: Date;
      file?: File;
    }>
  >([]);
  const contentRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLDivElement>(null);

  const handleFileUpload = (file: File | null) => {
    setUploadedFile(file);
    // æ–‡ä»¶ä¸Šä¼ åä¸è‡ªåŠ¨å‘é€å¯¹è¯ï¼Œåªæ˜¯è®¾ç½®æ–‡ä»¶çŠ¶æ€
    // ç”¨æˆ·å¯ä»¥é€šè¿‡åç»­çš„å¯¹è¯æ¥å¤„ç†æ–‡ä»¶
  };

  const handleClearFile = () => {
    setUploadedFile(null);
    // æ·»åŠ æ¸…é™¤æ–‡ä»¶æ¶ˆæ¯
    const clearMessage = {
      id: Date.now(),
      type: 'text',
      content: 'å·²æ¸…é™¤ä¸Šä¼ çš„æ–‡ä»¶',
      sender: 'user' as const,
      timestamp: new Date(),
    };
    setMessages((prev) => [...prev, clearMessage]);
  };

  // ç”ŸæˆåŸºäºä¸Šä¸‹æ–‡çš„æ¨¡æ‹Ÿå›å¤
  const generateMockResponse = (input: string, file?: File | null): string => {
    const lowerInput = input.toLowerCase();

    // åŸºç¡€å›å¤æ¨¡æ¿ - å¢å¼ºç‰ˆ Markdown æ ¼å¼
    const responses = {
      greeting: [
        `ä½ å¥½ï¼ğŸ‘‹ æˆ‘æ˜¯AIæ•°æ®æ²»ç†åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚

## æˆ‘çš„æ ¸å¿ƒèƒ½åŠ›
| åŠŸèƒ½é¢†åŸŸ | å…·ä½“æœåŠ¡ | ä¸“ä¸šç¨‹åº¦ |
|----------|----------|----------|
| ğŸ“Š **æ•°æ®åˆ†æ** | ç»Ÿè®¡åˆ†æã€è¶‹åŠ¿åˆ†æã€å¼‚å¸¸æ£€æµ‹ | â­â­â­â­â­ |
| ğŸ—‚ï¸ **æ•°æ®åˆ†ç±»** | æ™ºèƒ½åˆ†ç±»ã€æ ‡ç­¾ç®¡ç†ã€æ•°æ®æ•´ç† | â­â­â­â­â­ |
| ğŸ›¡ï¸ **æ•°æ®æ²»ç†** | è´¨é‡ç®¡ç†ã€æ ‡å‡†åŒ–ã€åˆè§„æ£€æŸ¥ | â­â­â­â­â­ |
| ğŸ“ **æ–‡ä»¶å¤„ç†** | Excelã€CSVã€JSONç­‰æ ¼å¼å¤„ç† | â­â­â­â­â­ |

è¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼`,
        `æ‚¨å¥½ï¼ğŸ’¼ æˆ‘æ˜¯ä¸“ä¸šçš„AIæ•°æ®æ²»ç†åŠ©æ‰‹ã€‚

### ğŸ¯ æœåŠ¡ç‰¹è‰²
- **ğŸš€ é«˜æ•ˆå¤„ç†**ï¼šå¿«é€Ÿåˆ†æå¤§è§„æ¨¡æ•°æ®é›†
- **ğŸ” ç²¾å‡†è¯†åˆ«**ï¼šæ™ºèƒ½å‘ç°æ•°æ®é—®é¢˜å’Œæ¨¡å¼
- **ğŸ“‹ ä¸“ä¸šå»ºè®®**ï¼šæä¾›è¡Œä¸šæœ€ä½³å®è·µæ–¹æ¡ˆ
- **ğŸ”§ å®ç”¨å·¥å…·**ï¼šå†…ç½®å¤šç§æ•°æ®å¤„ç†å‡½æ•°

æœ‰ä»€ä¹ˆæ•°æ®æ²»ç†æ–¹é¢çš„æŒ‘æˆ˜éœ€è¦è§£å†³å—ï¼Ÿ`,
        `ä½ å¥½ï¼ğŸ‰ æˆ‘å¯ä»¥ååŠ©ä½ è¿›è¡Œå„ç§æ•°æ®æ²»ç†ä»»åŠ¡ã€‚

### ğŸ’¡ æˆ‘çš„ä¼˜åŠ¿
\`\`\`python
# æ•°æ®å¤„ç†èƒ½åŠ›ç¤ºä¾‹
def data_quality_analysis(df):
    return {
        'completeness': check_completeness(df),
        'accuracy': validate_accuracy(df),
        'consistency': ensure_consistency(df),
        'uniqueness': verify_uniqueness(df)
    }
\`\`\`

**æ”¯æŒçš„æ•°æ®æ ¼å¼**ï¼šCSVã€Excelã€JSONã€æ•°æ®åº“ã€APIç­‰

æœ‰ä»€ä¹ˆå…·ä½“éœ€æ±‚å—ï¼Ÿ`,
      ],
      dataAnalysis: [
        `## ğŸ“Š æ•°æ®åˆ†æä¸“ä¸šæŠ¥å‘Š

### ğŸ” æ•°æ®è´¨é‡è¯„ä¼°
| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ | å»ºè®® |
|------|------|------|------|
| æ€»è®°å½•æ•° | 15,234 | âœ… æ­£å¸¸ | ä¿æŒå½“å‰è§„æ¨¡ |
| ç¼ºå¤±å€¼ç‡ | 2.3% | âš ï¸ éœ€å…³æ³¨ | å»ºè®®å¡«å……æˆ–åˆ é™¤ |
| é‡å¤è®°å½• | 127 | âŒ éœ€å¤„ç† | ç«‹å³å»é‡ |
| å¼‚å¸¸å€¼ | 89 | âš ï¸ éœ€å…³æ³¨ | è¿›ä¸€æ­¥éªŒè¯ |

### ğŸ“ˆ è¶‹åŠ¿åˆ†æ
\`\`\`sql
-- æ•°æ®è¶‹åŠ¿æŸ¥è¯¢ç¤ºä¾‹
SELECT 
    DATE(created_at) as date,
    COUNT(*) as record_count,
    AVG(value) as avg_value
FROM data_table 
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY DATE(created_at)
ORDER BY date;
\`\`\`

### ğŸ¯ å…³é”®å‘ç°
1. **ğŸ“… æ—¶é—´æ¨¡å¼**ï¼šå·¥ä½œæ—¥æ•°æ®é‡æ˜æ˜¾é«˜äºå‘¨æœ«
2. **ğŸ“Š æ•°å€¼åˆ†å¸ƒ**ï¼šç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œå‡å€¼ç¨³å®š
3. **âš ï¸ å¼‚å¸¸æ£€æµ‹**ï¼šå‘ç°3ä¸ªå¼‚å¸¸å³°å€¼éœ€è¦è°ƒæŸ¥

è¯·å‘Šè¯‰æˆ‘ä½ å¸Œæœ›æ·±å…¥åˆ†æå“ªä¸ªæ–¹é¢ï¼Ÿ`,
        `## ğŸ”¬ æ•°æ®æ·±åº¦åˆ†ææ–¹æ¡ˆ

### ğŸ“‹ åˆ†ææ­¥éª¤æ¸…å•
#### âœ… ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®æ¦‚è§ˆ
- [x] æ•°æ®åŸºæœ¬ä¿¡æ¯ç»Ÿè®¡
- [x] ç¼ºå¤±å€¼å’Œé‡å¤å€¼æ£€æŸ¥
- [x] æ•°æ®ç±»å‹éªŒè¯

#### ğŸ”„ ç¬¬äºŒé˜¶æ®µï¼šæ·±å…¥åˆ†æ
- [ ] ç›¸å…³æ€§åˆ†æ
- [ ] èšç±»åˆ†æ
- [ ] å¼‚å¸¸æ£€æµ‹

#### ğŸ¯ ç¬¬ä¸‰é˜¶æ®µï¼šæ´å¯Ÿæå–
- [ ] è¶‹åŠ¿é¢„æµ‹
- [ ] å…³é”®æŒ‡æ ‡è¯†åˆ«
- [ ] ä¸šåŠ¡å»ºè®®ç”Ÿæˆ

### ğŸ› ï¸ æ¨èå·¥å…·
\`\`\`python
# æ•°æ®åˆ†æå·¥å…·åŒ…
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
\`\`\`

ä½ å¸Œæœ›ä»å“ªä¸ªé˜¶æ®µå¼€å§‹ï¼Ÿ`,
        `## ğŸ“ˆ æ•°æ®åˆ†ææ–¹æ³•è®º

### ğŸ¨ åˆ†æç»´åº¦
\`\`\`mermaid
graph TD
    A[åŸå§‹æ•°æ®] --> B[æ•°æ®æ¸…æ´—]
    B --> C[æ¢ç´¢æ€§åˆ†æ]
    C --> D[ç»Ÿè®¡åˆ†æ]
    D --> E[æœºå™¨å­¦ä¹ ]
    E --> F[ä¸šåŠ¡æ´å¯Ÿ]
\`\`\`

### ğŸ“Š å…³é”®æŒ‡æ ‡çœ‹æ¿
| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | è¶‹åŠ¿ |
|----------|----------|--------|--------|------|
| **æ•°æ®è´¨é‡** | å®Œæ•´æ€§ | 97.7% | >99% | ğŸ“ˆ |
| **æ•°æ®è´¨é‡** | å‡†ç¡®æ€§ | 94.2% | >95% | ğŸ“ˆ |
| **ä¸šåŠ¡ä»·å€¼** | è½¬åŒ–ç‡ | 23.5% | >25% | ğŸ“‰ |
| **æŠ€æœ¯æ€§èƒ½** | å¤„ç†é€Ÿåº¦ | 1.2s | <1s | ğŸ“‰ |

### ğŸ’¡ æ”¹è¿›å»ºè®®
1. **ğŸ”§ ä¼˜åŒ–æ•°æ®ç®¡é“**ï¼šæå‡å¤„ç†æ•ˆç‡
2. **ğŸ“Š å¢å¼ºç›‘æ§**ï¼šå®æ—¶æ•°æ®è´¨é‡ç›‘æ§
3. **ğŸ¤– è‡ªåŠ¨åŒ–åˆ†æ**ï¼šå‡å°‘äººå·¥å¹²é¢„

éœ€è¦æˆ‘è¯¦ç»†è§£é‡ŠæŸä¸ªæ–¹é¢å—ï¼Ÿ`,
      ],
      fileProcessing: [
        `## ğŸ“ æ–‡ä»¶å¤„ç†åˆ†ææŠ¥å‘Š

### ğŸ“‹ æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
| å±æ€§ | å€¼ | è¯„ä¼° |
|------|-----|------|
| **æ–‡ä»¶å** | ${file?.name || 'data.csv'} | âœ… æ ‡å‡†æ ¼å¼ |
| **æ–‡ä»¶å¤§å°** | ${
          file ? `${Math.round(file.size / 1024)}KB` : '1.2MB'
        } | âœ… é€‚ä¸­å¤§å° |
| **æ–‡ä»¶ç±»å‹** | ${file?.type || 'text/csv'} | âœ… æ”¯æŒæ ¼å¼ |
| **é¢„ä¼°è®°å½•æ•°** | ${
          file ? `${Math.floor(Math.random() * 10000 + 5000)}` : '8,456'
        } | âœ… å¯å¤„ç†è§„æ¨¡ |

### ğŸ” æ•°æ®é¢„è§ˆ
\`\`\`csv
id,name,category,value,status,created_at
1,äº§å“A,ç”µå­,125.50,active,2024-01-15
2,äº§å“B,æœè£…,89.99,pending,2024-01-16
3,äº§å“C,é£Ÿå“,45.00,active,2024-01-17
... (å…± ${file ? `${Math.floor(Math.random() * 10000 + 5000)}` : '8,456'} è¡Œ)
\`\`\`

### ğŸ“Š æ•°æ®ç»“æ„åˆ†æ
| åˆ—å | æ•°æ®ç±»å‹ | éç©ºå€¼ | å”¯ä¸€å€¼ | è´¨é‡ |
|------|----------|--------|--------|------|
| id | integer | 100% | 100% | âœ… å®Œç¾ |
| name | string | 99.8% | 95.2% | âœ… è‰¯å¥½ |
| category | string | 100% | 12 | âœ… æ­£å¸¸ |
| value | decimal | 99.5% | - | âš ï¸ éœ€å…³æ³¨ |
| status | string | 100% | 3 | âœ… æ­£å¸¸ |

### ğŸ› ï¸ å¤„ç†å»ºè®®
#### ğŸ”¥ é«˜ä¼˜å…ˆçº§
1. **æ•°æ®æ¸…æ´—**
   - å¤„ç† value åˆ—çš„ç¼ºå¤±å€¼ (0.5%)
   - éªŒè¯ name åˆ—çš„å”¯ä¸€æ€§

#### âš ï¸ ä¸­ä¼˜å…ˆçº§
2. **æ•°æ®ä¼˜åŒ–**
   - category åˆ—æ ‡å‡†åŒ–
   - æ·»åŠ æ•°æ®éªŒè¯è§„åˆ™

#### ğŸ’¡ ä½ä¼˜å…ˆçº§
3. **åŠŸèƒ½å¢å¼º**
   - åˆ›å»ºæ•°æ®ç´¢å¼•
   - å»ºç«‹æ›´æ–°æœºåˆ¶

å¸Œæœ›æŒ‰å“ªç§æ–¹æ¡ˆå¤„ç†ï¼Ÿ`,
        `## ğŸ¯ æ–‡ä»¶æ•°æ®å¤„ç†æ–¹æ¡ˆ

### ğŸ“Š æ–‡ä»¶åˆ†ææ‘˜è¦
\`\`\`json
{
  "file_info": {
    "name": "${file?.name || 'dataset.csv'}",
    "size": "${file ? `${Math.round(file.size / 1024)}KB` : '2.1MB'}",
    "type": "${file?.type || 'application/csv'}",
    "encoding": "UTF-8"
  },
  "data_summary": {
    "total_rows": ${
      file ? `${Math.floor(Math.random() * 20000 + 10000)}` : '15,234'
    },
    "total_columns": 8,
    "memory_usage": "4.2MB"
  }
}
\`\`\`

### ğŸ”§ æ•°æ®å¤„ç†æµç¨‹
\`\`\`mermaid
graph LR
    A[æ–‡ä»¶ä¸Šä¼ ] --> B[æ ¼å¼æ£€æµ‹]
    B --> C[æ•°æ®è§£æ]
    C --> D[è´¨é‡æ£€æŸ¥]
    D --> E[æ•°æ®æ¸…æ´—]
    E --> F[ç»“æ„åŒ–å¤„ç†]
    F --> G[åˆ†ææŠ¥å‘Š]
\`\`\`

### ğŸ“ˆ å¤„ç†ç»“æœé¢„è§ˆ
#### æ•°æ®è´¨é‡è¯„åˆ†
| ç»´åº¦ | å¾—åˆ† | æ»¡åˆ† | çŠ¶æ€ |
|------|------|------|------|
| å®Œæ•´æ€§ | 92/100 | 100 | âš ï¸ è‰¯å¥½ |
| å‡†ç¡®æ€§ | 88/100 | 100 | âš ï¸ è‰¯å¥½ |
| ä¸€è‡´æ€§ | 95/100 | 100 | âœ… ä¼˜ç§€ |
| åŠæ—¶æ€§ | 100/100 | 100 | âœ… å®Œç¾ |

#### æ¨èæ“ä½œ
\`\`\`python
# æ•°æ®å¤„ç†è„šæœ¬ç¤ºä¾‹
import pandas as pd

def process_file(file_path):
    # è¯»å–æ–‡ä»¶
    df = pd.read_csv(file_path)
    
    # æ•°æ®æ¸…æ´—
    df = df.drop_duplicates()
    df = df.fillna(method='ffill')
    
    # æ•°æ®éªŒè¯
    assert df.isnull().sum().sum() == 0
    
    return df
\`\`\`

ä½ å¸Œæœ›æˆ‘æ‰§è¡Œå“ªç§å¤„ç†æ–¹æ¡ˆï¼Ÿ`,
        `## ğŸš€ æ–‡ä»¶å†…å®¹æ™ºèƒ½åˆ†æ

### ğŸ“‹ æ–‡ä»¶å…ƒæ•°æ®
| ç‰¹æ€§ | æè¿° | å€¼ |
|------|------|-----|
| **æ–‡ä»¶æ ‡è¯†** | å”¯ä¸€ID | FILE_${Date.now()} |
| **å¤„ç†çŠ¶æ€** | å½“å‰è¿›åº¦ | 100% å®Œæˆ |
| **é£é™©ç­‰çº§** | æ•°æ®é£é™© | ğŸŸ¡ ä½é£é™© |
| **æ¨èè¡ŒåŠ¨** | ä¸‹ä¸€æ­¥ | âœ… å¯å®‰å…¨å¤„ç† |

### ğŸ¯ å†…å®¹åˆ†æç»“æœ
#### æ•°æ®åˆ†å¸ƒæ¦‚è§ˆ
\`\`\`
å­—æ®µç»Ÿè®¡ä¿¡æ¯ï¼š
- æ•°å€¼å‹å­—æ®µ: 4ä¸ª
- åˆ†ç±»å‹å­—æ®µ: 3ä¸ª  
- æ—¥æœŸå‹å­—æ®µ: 1ä¸ª
- æ–‡æœ¬å‹å­—æ®µ: 2ä¸ª
\`\`\`

#### è´¨é‡è¯„ä¼°çŸ©é˜µ
| è´¨é‡ç»´åº¦ | è¯„åˆ† | é—®é¢˜æ•°é‡ | ä¸¥é‡ç¨‹åº¦ |
|----------|------|----------|----------|
| å®Œæ•´æ€§ | 9.2/10 | 23 | ğŸŸ¡ è½»å¾® |
| å”¯ä¸€æ€§ | 9.8/10 | 5 | ğŸŸ¢ æå¥½ |
| æœ‰æ•ˆæ€§ | 8.9/10 | 45 | ğŸŸ¡ è½»å¾® |
| ä¸€è‡´æ€§ | 9.5/10 | 12 | ğŸŸ¢ æå¥½ |

### ğŸ› ï¸ å¤„ç†å»ºè®®æ¸…å•
#### âœ… ç«‹å³æ‰§è¡Œ
1. **åŸºç¡€æ¸…æ´—**
   - ç§»é™¤å®Œå…¨é‡å¤çš„è®°å½•
   - å¡«å……æ˜æ˜¾çš„ç¼ºå¤±å€¼

#### ğŸ”„ è®¡åˆ’æ‰§è¡Œ  
2. **æ·±åº¦å¤„ç†**
   - æ ‡å‡†åŒ–åˆ†ç±»å­—æ®µ
   - éªŒè¯æ•°å€¼èŒƒå›´åˆç†æ€§

#### ğŸ“‹ åç»­ä¼˜åŒ–
3. **é•¿æœŸç»´æŠ¤**
   - å»ºç«‹æ•°æ®è´¨é‡ç›‘æ§
   - è®¾ç½®è‡ªåŠ¨åŒ–éªŒè¯è§„åˆ™

### ğŸ’¼ ä¸šåŠ¡ä»·å€¼è¯„ä¼°
\`\`\`markdown
## ROI åˆ†æ
- **æ•°æ®è´¨é‡æå‡**: é¢„è®¡ 35%
- **å¤„ç†æ•ˆç‡æå‡**: é¢„è®¡ 60%  
- **å†³ç­–å‡†ç¡®æ€§**: é¢„è®¡ 45%
- **æ€»ä½“æŠ•èµ„å›æŠ¥**: é¢„è®¡ 280%
\`\`\`

éœ€è¦æˆ‘å¼€å§‹æ‰§è¡Œå¤„ç†æµç¨‹å—ï¼Ÿ`,
      ],
      help: [
        `## ğŸ¯ AIæ•°æ®æ²»ç†åŠ©æ‰‹ - å®Œæ•´æœåŠ¡æŒ‡å—

### ğŸ“Š æ ¸å¿ƒæœåŠ¡çŸ©é˜µ
| æœåŠ¡ç±»åˆ« | å…·ä½“åŠŸèƒ½ | æŠ€æœ¯æ ˆ | é€‚ç”¨åœºæ™¯ |
|----------|----------|--------|----------|
| **ğŸ” æ•°æ®åˆ†æ** | ç»Ÿè®¡åˆ†æã€è¶‹åŠ¿é¢„æµ‹ã€å¼‚å¸¸æ£€æµ‹ | Python, R, SQL | ä¸šåŠ¡å†³ç­–æ”¯æŒ |
| **ğŸ—‚ï¸ æ•°æ®åˆ†ç±»** | æ™ºèƒ½æ ‡æ³¨ã€è‡ªåŠ¨åˆ†ç±»ã€æ ‡ç­¾ç®¡ç† | ML, NLP, è§„åˆ™å¼•æ“ | å†…å®¹ç»„ç»‡ç®¡ç† |
| **ğŸ›¡ï¸ æ•°æ®æ²»ç†** | è´¨é‡ç›‘æ§ã€æ ‡å‡†åŒ–ã€åˆè§„æ£€æŸ¥ | æ•°æ®è´¨é‡å·¥å…·, å…ƒæ•°æ®ç®¡ç† | ä¼ä¸šæ•°æ®ç®¡ç† |
| **ğŸ“ æ–‡ä»¶å¤„ç†** | å¤šæ ¼å¼è§£æã€æ•°æ®è½¬æ¢ã€æ‰¹é‡å¤„ç† | ETLå·¥å…·, è§£æåº“ | æ•°æ®é›†æˆå·¥ç¨‹ |

### ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

#### 1ï¸âƒ£ æ•°æ®åˆ†ææœåŠ¡
\`\`\`python
# æ•°æ®åˆ†æç¤ºä¾‹
import pandas as pd
import numpy as np

def comprehensive_analysis(df):
    """å…¨é¢æ•°æ®åˆ†æ"""
    report = {
        'basic_stats': df.describe(),
        'quality_score': calculate_quality_score(df),
        'anomalies': detect_anomalies(df),
        'trends': analyze_trends(df)
    }
    return report
\`\`\`

**ä½¿ç”¨åœºæ™¯ï¼š**
- ğŸ“ˆ ä¸šåŠ¡æ•°æ®è¶‹åŠ¿åˆ†æ
- ğŸ” æ•°æ®è´¨é‡é—®é¢˜è¯†åˆ«  
- ğŸ“Š ç»Ÿè®¡æŠ¥å‘Šç”Ÿæˆ

#### 2ï¸âƒ£ æ•°æ®åˆ†ç±»æœåŠ¡
\`\`\`python
# æ™ºèƒ½åˆ†ç±»ç¤ºä¾‹
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB

def intelligent_classification(data, categories):
    """æ™ºèƒ½æ•°æ®åˆ†ç±»"""
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(data)
    
    classifier = MultinomialNB()
    classifier.fit(X, categories)
    
    return classifier
\`\`\`

**åˆ†ç±»ç±»å‹ï¼š**
- ğŸ·ï¸ å†…å®¹ä¸»é¢˜åˆ†ç±»
- ğŸ“‚ æ–‡æ¡£ç±»å‹è¯†åˆ«
- ğŸ‘¥ ç”¨æˆ·ç”»åƒåˆ†ç¾¤

#### 3ï¸âƒ£ æ•°æ®æ²»ç†æœåŠ¡
\`\`\`python
# æ•°æ®æ²»ç†æ¡†æ¶
class DataGovernanceFramework:
    def __init__(self):
        self.quality_rules = self._load_quality_rules()
        self.compliance_standards = self._load_standards()
    
    def audit_data_quality(self, dataset):
        """æ•°æ®è´¨é‡å®¡è®¡"""
        return {
            'completeness': self.check_completeness(dataset),
            'accuracy': self.validate_accuracy(dataset),
            'consistency': self.ensure_consistency(dataset)
        }
\`\`\`

**æ²»ç†èŒƒå›´ï¼š**
- ğŸ“‹ æ•°æ®æ ‡å‡†åˆ¶å®š
- ğŸ” è´¨é‡ç›‘æ§å‘Šè­¦
- ğŸ“Š åˆè§„æ€§æ£€æŸ¥

#### 4ï¸âƒ£ æ–‡ä»¶å¤„ç†æœåŠ¡
\`\`\`python
# å¤šæ ¼å¼æ–‡ä»¶å¤„ç†
class FileProcessor:
    def __init__(self):
        self.supported_formats = ['csv', 'xlsx', 'json', 'xml', 'parquet']
    
    def process_file(self, file_path, operations):
        """æ–‡ä»¶å¤„ç†æµæ°´çº¿"""
        result = {
            'original_file': file_path,
            'operations_applied': operations,
            'output_files': [],
            'processing_log': []
        }
        
        return self._execute_pipeline(result)
\`\`\`

**å¤„ç†èƒ½åŠ›ï¼š**
- ğŸ“ å¤šæ ¼å¼æ”¯æŒ
- ğŸ”„ æ‰¹é‡å¤„ç†
- ğŸ“‹ è½¬æ¢éªŒè¯

### ğŸ’¡ æœ€ä½³å®è·µå»ºè®®

#### ğŸ¯ æ•°æ®åˆ†ææœ€ä½³å®è·µ
1. **æ˜ç¡®åˆ†æç›®æ ‡**
   - å®šä¹‰å…³é”®ä¸šåŠ¡é—®é¢˜
   - ç¡®å®šæˆåŠŸæŒ‡æ ‡

2. **æ•°æ®è´¨é‡ä¼˜å…ˆ**
   - å…ˆæ¸…æ´—ï¼Œååˆ†æ
   - å»ºç«‹æ•°æ®è´¨é‡åŸºçº¿

3. **è¿­ä»£åˆ†ææ–¹æ³•**
   - ä»æè¿°æ€§åˆ†æå¼€å§‹
   - é€æ­¥æ·±å…¥åˆ°é¢„æµ‹æ€§åˆ†æ

#### ğŸ›¡ï¸ æ•°æ®æ²»ç†æœ€ä½³å®è·µ
1. **å»ºç«‹æ²»ç†æ¡†æ¶**
   - åˆ¶å®šæ•°æ®æ ‡å‡†
   - æ˜ç¡®è´£ä»»åˆ†å·¥

2. **æŒç»­ç›‘æ§æœºåˆ¶**
   - å®æ—¶è´¨é‡ç›‘æ§
   - å®šæœŸåˆè§„å®¡è®¡

3. **æŠ€æœ¯å·¥å…·æ”¯æ’‘**
   - è‡ªåŠ¨åŒ–æ²»ç†å·¥å…·
   - å…ƒæ•°æ®ç®¡ç†å¹³å°

### ğŸ“ è”ç³»æ”¯æŒ
å¦‚éœ€å®šåˆ¶åŒ–è§£å†³æ–¹æ¡ˆï¼Œè¯·æä¾›ï¼š
- ğŸ“‹ å…·ä½“ä¸šåŠ¡éœ€æ±‚
- ğŸ“Š å½“å‰æ•°æ®çŠ¶å†µ  
- ğŸ¯ æœŸæœ›è¾¾æˆç›®æ ‡
- â° é¡¹ç›®æ—¶é—´è¦æ±‚

æˆ‘å·²å‡†å¤‡å¥½ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æ•°æ®æ²»ç†æœåŠ¡ï¼`,
        `## ğŸ› ï¸ æ•°æ®æ²»ç†å·¥å…·ç®± - å®ç”¨æŒ‡å—

### ğŸ¯ æˆ‘çš„æ ¸å¿ƒèƒ½åŠ›è¯¦è§£

#### ğŸ” æ•°æ®åˆ†ææ¨¡å—
##### ç»Ÿè®¡åˆ†æå¥—ä»¶
\`\`\`python
# å…¨é¢ç»Ÿè®¡åˆ†æå·¥å…·
class StatisticalAnalyzer:
    def __init__(self):
        self.methods = ['descriptive', 'inferential', 'predictive']
    
    def descriptive_analysis(self, data):
        """æè¿°æ€§ç»Ÿè®¡åˆ†æ"""
        return {
            'central_tendency': {
                'mean': data.mean(),
                'median': data.median(),
                'mode': data.mode().iloc[0]
            },
            'dispersion': {
                'std': data.std(),
                'variance': data.var(),
                'range': data.max() - data.min()
            },
            'distribution': {
                'skewness': data.skew(),
                'kurtosis': data.kurtosis()
            }
        }
    
    def correlation_analysis(self, data):
        """ç›¸å…³æ€§åˆ†æ"""
        correlation_matrix = data.corr()
        strong_correlations = []
        
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                corr_val = correlation_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:
                    strong_correlations.append({
                        'var1': correlation_matrix.columns[i],
                        'var2': correlation_matrix.columns[j],
                        'correlation': corr_val
                    })
        
        return {
            'correlation_matrix': correlation_matrix,
            'strong_correlations': strong_correlations
        }
\`\`\`

**åº”ç”¨åœºæ™¯ï¼š**
- ğŸ“ˆ ä¸šåŠ¡æŒ‡æ ‡è¶‹åŠ¿åˆ†æ
- ğŸ” å˜é‡å…³ç³»æŒ–æ˜
- ğŸ“Š æ•°æ®è´¨é‡è¯„ä¼°

#### ğŸ—‚ï¸ æ•°æ®åˆ†ç±»å¼•æ“
##### æœºå™¨å­¦ä¹ åˆ†ç±»
\`\`\`python
# æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ
import torch
import torch.nn as nn
from transformers import BertTokenizer, BertModel

class IntelligentClassifier:
    def __init__(self):
        self.tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
        self.model = BertModel.from_pretrained('bert-base-chinese')
        self.classifier = nn.Sequential(
            nn.Linear(768, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, len(self.categories))
        )
    
    def classify_text(self, text, categories):
        """æ–‡æœ¬æ™ºèƒ½åˆ†ç±»"""
        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True)
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            embeddings = outputs.last_hidden_state.mean(dim=1)
            logits = self.classifier(embeddings)
            probabilities = torch.softmax(logits, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1)
        
        return {
            'predicted_category': categories[predicted_class.item()],
            'confidence': probabilities.max().item(),
            'all_probabilities': {
                cat: prob.item() 
                for cat, prob in zip(categories, probabilities[0])
            }
        }
\`\`\`

**åˆ†ç±»èƒ½åŠ›ï¼š**
- ğŸ“ æ–‡æ¡£ä¸»é¢˜åˆ†ç±»
- ğŸ‘¤ ç”¨æˆ·ç”»åƒåˆ†ç¾¤
- ğŸ·ï¸ äº§å“æ ‡ç­¾ç®¡ç†

#### ğŸ›¡ï¸ æ•°æ®æ²»ç†æ¡†æ¶
##### è´¨é‡ç›‘æ§ä½“ç³»
\`\`\`python
# æ•°æ®è´¨é‡ç›‘æ§ç³»ç»Ÿ
class DataQualityMonitor:
    def __init__(self):
        self.quality_dimensions = {
            'completeness': self.check_completeness,
            'accuracy': self.check_accuracy,
            'consistency': self.check_consistency,
            'timeliness': self.check_timeliness,
            'validity': self.check_validity,
            'uniqueness': self.check_uniqueness
        }
    
    def comprehensive_audit(self, dataset):
        """å…¨é¢æ•°æ®è´¨é‡å®¡è®¡"""
        audit_results = {}
        
        for dimension, check_func in self.quality_dimensions.items():
            try:
                result = check_func(dataset)
                audit_results[dimension] = {
                    'score': result['score'],
                    'issues': result['issues'],
                    'recommendations': result['recommendations'],
                    'status': self._evaluate_status(result['score'])
                }
            except Exception as e:
                audit_results[dimension] = {
                    'score': 0,
                    'issues': [f'æ£€æŸ¥å¤±è´¥: {str(e)}'],
                    'recommendations': ['ä¿®å¤æ£€æŸ¥é€»è¾‘'],
                    'status': 'error'
                }
        
        overall_score = np.mean([result['score'] for result in audit_results.values()])
        
        return {
            'overall_score': overall_score,
            'overall_status': self._evaluate_status(overall_score),
            'dimension_scores': audit_results,
            'priority_actions': self._generate_priority_actions(audit_results)
        }
\`\`\`

**æ²»ç†åŠŸèƒ½ï¼š**
- ğŸ“Š å®æ—¶è´¨é‡ç›‘æ§
- ğŸ” å¼‚å¸¸æ£€æµ‹å‘Šè­¦
- ğŸ“‹ åˆè§„æ€§æ£€æŸ¥

#### ğŸ“ æ–‡ä»¶å¤„ç†å·¥å…·é“¾
##### å¤šæ ¼å¼å¤„ç†å¼•æ“
\`\`\`python
# ç»Ÿä¸€æ–‡ä»¶å¤„ç†å™¨
class UniversalFileProcessor:
    def __init__(self):
        self.format_handlers = {
            'csv': self._handle_csv,
            'xlsx': self._handle_excel,
            'json': self._handle_json,
            'xml': self._handle_xml,
            'parquet': self._handle_parquet,
            'avro': self._handle_avro
        }
    
    def process_pipeline(self, file_path, config):
        """æ–‡ä»¶å¤„ç†æµæ°´çº¿"""
        pipeline_results = {
            'file_info': self._extract_file_info(file_path),
            'validation_results': self._validate_file(file_path),
            'processing_steps': [],
            'output_files': [],
            'quality_metrics': {},
            'processing_log': []
        }
        
        # æ‰§è¡Œå¤„ç†æ­¥éª¤
        for step in config['processing_steps']:
            step_result = self._execute_processing_step(
                file_path, step, pipeline_results
            )
            pipeline_results['processing_steps'].append(step_result)
            
            if step_result['status'] == 'error':
                break
        
        # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
        pipeline_results['quality_metrics'] = self._generate_quality_report(
            pipeline_results
        )
        
        return pipeline_results
    
    def _execute_processing_step(self, file_path, step_config, context):
        """æ‰§è¡Œå•ä¸ªå¤„ç†æ­¥éª¤"""
        step_type = step_config['type']
        step_params = step_config.get('parameters', {})
        
        try:
            if step_type == 'read':
                data = self._read_file(file_path, step_params)
                return {'status': 'success', 'data': data, 'output': None}
            
            elif step_type == 'clean':
                cleaned_data = self._clean_data(context['data'], step_params)
                return {'status': 'success', 'data': cleaned_data, 'output': None}
            
            elif step_type == 'transform':
                transformed_data = self._transform_data(
                    context['data'], step_params
                )
                return {'status': 'success', 'data': transformed_data, 'output': None}
            
            elif step_type == 'validate':
                validation_result = self._validate_data(
                    context['data'], step_params
                )
                return {'status': 'success', 'data': context['data'], 
                       'output': validation_result}
            
            elif step_type == 'export':
                output_path = self._export_data(
                    context['data'], step_params
                )
                return {'status': 'success', 'data': context['data'], 
                       'output': output_path}
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e),
                'data': context.get('data'),
                'output': None
            }
\`\`\`

**å¤„ç†èƒ½åŠ›ï¼š**
- ğŸ”„ å¤šæ ¼å¼æ”¯æŒ
- âš¡ é«˜æ€§èƒ½å¤„ç†
- ğŸ“‹ è´¨é‡éªŒè¯

### ğŸ¯ é€‰æ‹©å»ºè®®
æ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæˆ‘æ¨èï¼š

1. **ğŸ“Š æ•°æ®åˆ†æéœ€æ±‚** â†’ ä½¿ç”¨ç»Ÿè®¡åˆ†æå¥—ä»¶
2. **ğŸ—‚ï¸ å†…å®¹æ•´ç†éœ€æ±‚** â†’ ä½¿ç”¨æ™ºèƒ½åˆ†ç±»å¼•æ“  
3. **ğŸ›¡ï¸ è´¨é‡ç®¡ç†éœ€æ±‚** â†’ ä½¿ç”¨æ²»ç†ç›‘æ§æ¡†æ¶
4. **ğŸ“ æ‰¹é‡å¤„ç†éœ€æ±‚** â†’ ä½¿ç”¨æ–‡ä»¶å¤„ç†å·¥å…·é“¾

è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å…·ä½“åœºæ™¯ï¼Œæˆ‘ä¼šä¸ºæ‚¨å®šåˆ¶æœ€ä½³è§£å†³æ–¹æ¡ˆï¼`,
        `## ğŸš€ æ•°æ®æ²»ç†èƒ½åŠ›å…¨æ™¯å›¾

### ğŸ“Š æˆ‘çš„æŠ€æœ¯æ ˆæ€»è§ˆ

#### ğŸ”§ æ ¸å¿ƒæŠ€æœ¯æ¶æ„
\`\`\`mermaid
graph TB
    A[ç”¨æˆ·ç•Œé¢] --> B[APIç½‘å…³]
    B --> C[ä¸šåŠ¡é€»è¾‘å±‚]
    C --> D[æ•°æ®å¤„ç†å¼•æ“]
    D --> E[å­˜å‚¨å±‚]
    
    C --> F[AIæ¨¡å‹æœåŠ¡]
    C --> G[è§„åˆ™å¼•æ“]
    C --> H[ç›‘æ§å‘Šè­¦]
    
    D --> I[æ•°æ®åˆ†ææ¨¡å—]
    D --> J[æ•°æ®åˆ†ç±»æ¨¡å—]
    D --> K[è´¨é‡æ£€æŸ¥æ¨¡å—]
    D --> L[æ–‡ä»¶å¤„ç†æ¨¡å—]
\`\`\`

### ğŸ¯ è¯¦ç»†èƒ½åŠ›çŸ©é˜µ

#### ğŸ“ˆ æ•°æ®åˆ†æèƒ½åŠ›
| èƒ½åŠ›ç»´åº¦ | å…·ä½“åŠŸèƒ½ | æŠ€æœ¯å®ç° | æˆç†Ÿåº¦ |
|----------|----------|----------|--------|
| **æè¿°æ€§åˆ†æ** | åŸºç¡€ç»Ÿè®¡ã€åˆ†å¸ƒåˆ†æ | Pandas, NumPy | â­â­â­â­â­ |
| **è¯Šæ–­æ€§åˆ†æ** | ç›¸å…³æ€§ã€å› æœåˆ†æ | SciPy, Statsmodels | â­â­â­â­â­ |
| **é¢„æµ‹æ€§åˆ†æ** | è¶‹åŠ¿é¢„æµ‹ã€æœºå™¨å­¦ä¹  | Scikit-learn, TensorFlow | â­â­â­â­ |
| **è§„èŒƒæ€§åˆ†æ** | ä¼˜åŒ–å»ºè®®ã€å†³ç­–æ”¯æŒ | OR-Tools, Gurobi | â­â­â­ |

**ç‰¹è‰²åŠŸèƒ½ï¼š**
- ğŸ” **å¼‚å¸¸æ£€æµ‹**ï¼šåŸºäºç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ çš„å¤šç»´åº¦å¼‚å¸¸è¯†åˆ«
- ğŸ“Š **å®æ—¶åˆ†æ**ï¼šæ”¯æŒæµå¼æ•°æ®çš„å®æ—¶ç»Ÿè®¡åˆ†æ
- ğŸ“ˆ **å¯è§†åŒ–æŠ¥å‘Š**ï¼šè‡ªåŠ¨ç”Ÿæˆä¸“ä¸šçš„æ•°æ®å¯è§†åŒ–æŠ¥å‘Š

#### ğŸ—‚ï¸ æ•°æ®åˆ†ç±»èƒ½åŠ›
| åˆ†ç±»ç±»å‹ | ç®—æ³•æ”¯æŒ | å‡†ç¡®ç‡ | å¤„ç†é€Ÿåº¦ |
|----------|----------|--------|----------|
| **æ–‡æœ¬åˆ†ç±»** | BERT, RoBERTa, TextCNN | 92-95% | ä¸­é€Ÿ |
| **å›¾åƒåˆ†ç±»** | ResNet, ViT, EfficientNet | 88-93% | ä¸­é€Ÿ |
| **ç»“æ„åŒ–æ•°æ®** | Random Forest, XGBoost | 85-90% | é«˜é€Ÿ |
| **æ—¶åºæ•°æ®** | LSTM, GRU, Transformer | 82-88% | ä¸­é€Ÿ |

**åº”ç”¨åœºæ™¯ï¼š**
- ğŸ“ **æ–‡æ¡£æ™ºèƒ½åˆ†ç±»**ï¼šè‡ªåŠ¨è¯†åˆ«æ–‡æ¡£ç±»å‹å’Œä¸»é¢˜
- ğŸ‘¥ **ç”¨æˆ·ç”»åƒåˆ†ç¾¤**ï¼šåŸºäºè¡Œä¸ºæ•°æ®çš„ç”¨æˆ·åˆ†ç¾¤
- ğŸ·ï¸ **äº§å“æ ‡ç­¾ç®¡ç†**ï¼šæ™ºèƒ½äº§å“åˆ†ç±»å’Œæ ‡ç­¾æ¨è

#### ğŸ›¡ï¸ æ•°æ®æ²»ç†èƒ½åŠ›
| æ²»ç†é¢†åŸŸ | æ ¸å¿ƒåŠŸèƒ½ | å·¥å…·æ”¯æŒ | è‡ªåŠ¨åŒ–ç¨‹åº¦ |
|----------|----------|----------|------------|
| **æ•°æ®è´¨é‡** | å®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€ä¸€è‡´æ€§æ£€æŸ¥ | è‡ªç ”è´¨é‡æ¡†æ¶ | 90% |
| **å…ƒæ•°æ®ç®¡ç†** | æ•°æ®å­—å…¸ã€è¡€ç¼˜è¿½è¸ª | Atlas, DataHub | 85% |
| **æ•°æ®å®‰å…¨** | è®¿é—®æ§åˆ¶ã€æ•æ„Ÿæ•°æ®å‘ç° | Ranger, Privacera | 80% |
| **åˆè§„ç®¡ç†** | æ³•è§„éµå¾ªã€å®¡è®¡è¿½è¸ª | è‡ªç ”åˆè§„å¼•æ“ | 75% |

**æ²»ç†ç‰¹è‰²ï¼š**
- ğŸ“Š **è´¨é‡è¯„åˆ†ä½“ç³»**ï¼šå¤šç»´åº¦æ•°æ®è´¨é‡é‡åŒ–è¯„ä¼°
- ğŸ” **è¡€ç¼˜è¿½è¸ª**ï¼šå®Œæ•´çš„æ•°æ®æµè½¬è·¯å¾„è¿½è¸ª
- ğŸ“‹ **åˆè§„æ£€æŸ¥**ï¼šè‡ªåŠ¨åŒ–çš„æ³•è§„éµå¾ªæ£€æŸ¥

#### ğŸ“ æ–‡ä»¶å¤„ç†èƒ½åŠ›
| æ–‡ä»¶æ ¼å¼ | è¯»å–é€Ÿåº¦ | å†™å…¥é€Ÿåº¦ | å‹ç¼©æ”¯æŒ | ç‰¹æ®ŠåŠŸèƒ½ |
|----------|----------|----------|----------|----------|
| **CSV** | âš¡ æå¿« | âš¡ æå¿« | âœ… æ”¯æŒ | å¤§æ–‡ä»¶åˆ†å—å¤„ç† |
| **Excel** | âš¡ å¿« | âš¡ å¿« | âœ… æ”¯æŒ | å¤šSheetå¤„ç† |
| **JSON** | âš¡ å¿« | âš¡ å¿« | âœ… æ”¯æŒ | SchemaéªŒè¯ |
| **Parquet** | âš¡ å¿« | âš¡ å¿« | âœ… æ”¯æŒ | åˆ—å¼å­˜å‚¨ä¼˜åŒ– |
| **Avro** | âš¡ å¿« | âš¡ å¿« | âœ… æ”¯æŒ | Schemaæ¼”åŒ– |
| **XML** | ğŸŒ æ…¢ | ğŸŒ æ…¢ | âœ… æ”¯æŒ | XPathæŸ¥è¯¢ |

**å¤„ç†ç‰¹è‰²ï¼š**
- ğŸ”„ **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒå¤§è§„æ¨¡æ–‡ä»¶çš„æ‰¹é‡å¤„ç†
- âš¡ **å†…å­˜ä¼˜åŒ–**ï¼šå¤§æ–‡ä»¶çš„æµå¼å¤„ç†ï¼Œå†…å­˜å ç”¨ä½
- ğŸ“‹ **æ ¼å¼è½¬æ¢**ï¼šæ”¯æŒå¤šç§æ ¼å¼é—´çš„ç›¸äº’è½¬æ¢

### ğŸ’¡ å®æ–½å»ºè®®

#### ğŸ¯ åˆ†é˜¶æ®µå®æ–½ç­–ç•¥
##### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€å»ºè®¾ (1-2ä¸ªæœˆ)
- [ ] æ­å»ºæ•°æ®å¤„ç†åŸºç¡€è®¾æ–½
- [ ] å®ç°åŸºç¡€æ•°æ®è´¨é‡æ£€æŸ¥
- [ ] éƒ¨ç½²æ–‡ä»¶å¤„ç†å¼•æ“

##### ç¬¬äºŒé˜¶æ®µï¼šèƒ½åŠ›å¢å¼º (2-3ä¸ªæœˆ)  
- [ ] é›†æˆæœºå™¨å­¦ä¹ åˆ†ç±»æ¨¡å‹
- [ ] å®ç°é«˜çº§æ•°æ®åˆ†æåŠŸèƒ½
- [ ] å»ºç«‹å…ƒæ•°æ®ç®¡ç†ä½“ç³»

##### ç¬¬ä¸‰é˜¶æ®µï¼šæ™ºèƒ½ä¼˜åŒ– (3-4ä¸ªæœˆ)
- [ ] éƒ¨ç½²AIé©±åŠ¨çš„æ™ºèƒ½æ¨è
- [ ] å®ç°å®æ—¶ç›‘æ§å‘Šè­¦
- [ ] å»ºç«‹è‡ªåŠ¨åŒ–æ²»ç†æµç¨‹

#### ğŸ“Š é¢„æœŸæ”¶ç›Š
| å®æ–½é˜¶æ®µ | æ•°æ®è´¨é‡æå‡ | å¤„ç†æ•ˆç‡æå‡ | æˆæœ¬é™ä½ | ROI |
|----------|--------------|--------------|----------|-----|
| **ç¬¬ä¸€é˜¶æ®µ** | 30% | 50% | 20% | 160% |
| **ç¬¬äºŒé˜¶æ®µ** | 50% | 80% | 35% | 250% |
| **ç¬¬ä¸‰é˜¶æ®µ** | 70% | 120% | 50% | 340% |

### ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨
æˆ‘å»ºè®®ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢å¼€å§‹ï¼š

1. **ğŸ” éœ€æ±‚è°ƒç ”**ï¼šæ·±å…¥äº†è§£æ‚¨çš„å…·ä½“ä¸šåŠ¡éœ€æ±‚
2. **ğŸ“Š ç°çŠ¶è¯„ä¼°**ï¼šè¯„ä¼°å½“å‰æ•°æ®æ²»ç†æˆç†Ÿåº¦
3. **ğŸ¯ æ–¹æ¡ˆè®¾è®¡**ï¼šå®šåˆ¶åŒ–è§£å†³æ–¹æ¡ˆè®¾è®¡
4. **ğŸš€ è¯•ç‚¹å®æ–½**ï¼šé€‰æ‹©å…³é”®åœºæ™¯è¿›è¡Œè¯•ç‚¹

è¯·å‘Šè¯‰æˆ‘æ‚¨æœ€å…³å¿ƒå“ªä¸ªæ–¹é¢ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›è¯¦ç»†çš„å®æ–½è®¡åˆ’ï¼`,
      ],
      default: [
        `## ğŸ’¡ ä¸“ä¸šæ•°æ®æ²»ç†å»ºè®®

æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼ä½œä¸ºä¸“ä¸šçš„AIæ•°æ®æ²»ç†åŠ©æ‰‹ï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä»¥ä¸‹å»ºè®®ï¼š

### ğŸ¯ å½“å‰æ•°æ®æ²»ç†æœ€ä½³å®è·µ

#### ğŸ“Š æ•°æ®è´¨é‡è¯„ä¼°æ¡†æ¶
\`\`\`python
# æ•°æ®è´¨é‡è¯„ä¼°æ¨¡å‹
class DataQualityFramework:
    def __init__(self):
        self.dimensions = {
            'completeness': 0.25,
            'accuracy': 0.25, 
            'consistency': 0.25,
            'timeliness': 0.25
        }
    
    def calculate_quality_score(self, dataset):
        """è®¡ç®—ç»¼åˆè´¨é‡è¯„åˆ†"""
        scores = {}
        for dimension, weight in self.dimensions.items():
            score = self._evaluate_dimension(dataset, dimension)
            scores[dimension] = score * weight
        
        total_score = sum(scores.values())
        return {
            'total_score': total_score,
            'dimension_scores': scores,
            'grade': self._score_to_grade(total_score)
        }
\`\`\`

#### ğŸ›¡ï¸ æ•°æ®æ²»ç†å…³é”®è¦ç´ 
| è¦ç´  | é‡è¦æ€§ | å®æ–½éš¾åº¦ | å»ºè®®ä¼˜å…ˆçº§ |
|------|--------|----------|------------|
| **æ•°æ®æ ‡å‡†** | ğŸ”´ é«˜ | ğŸŸ¡ ä¸­ç­‰ | P0 |
| **è´¨é‡ç›‘æ§** | ğŸ”´ é«˜ | ğŸŸ¢ ç®€å• | P0 |
| **å…ƒæ•°æ®ç®¡ç†** | ğŸŸ¡ ä¸­ç­‰ | ğŸŸ¡ ä¸­ç­‰ | P1 |
| **æ•°æ®å®‰å…¨** | ğŸ”´ é«˜ | ğŸ”´ å›°éš¾ | P1 |
| **ä¸»æ•°æ®ç®¡ç†** | ğŸŸ¡ ä¸­ç­‰ | ğŸ”´ å›°éš¾ | P2 |

### ğŸ“‹ å®æ–½è·¯çº¿å›¾

#### ğŸš€ ç¬¬ä¸€é˜¶æ®µ (0-3ä¸ªæœˆ)
1. **åŸºç¡€å»ºè®¾**
   - [ ] å»ºç«‹æ•°æ®æ ‡å‡†è§„èŒƒ
   - [ ] éƒ¨ç½²æ•°æ®è´¨é‡ç›‘æ§å·¥å…·
   - [ ] åˆ¶å®šæ•°æ®æ²»ç†æµç¨‹

#### ğŸ¯ ç¬¬äºŒé˜¶æ®µ (3-6ä¸ªæœˆ)
2. **èƒ½åŠ›æå‡**  
   - [ ] å®æ–½å…ƒæ•°æ®ç®¡ç†å¹³å°
   - [ ] å»ºç«‹æ•°æ®å®‰å…¨æ§åˆ¶
   - [ ] å¼€å±•æ•°æ®æ²»ç†åŸ¹è®­

#### ğŸ’¡ ç¬¬ä¸‰é˜¶æ®µ (6-12ä¸ªæœˆ)
3. **æ™ºèƒ½ä¼˜åŒ–**
   - [ ] å¼•å…¥AIé©±åŠ¨çš„æ•°æ®æ²»ç†
   - [ ] å»ºç«‹è‡ªåŠ¨åŒ–æ²»ç†æµç¨‹
   - [ ] å®ç°æŒç»­æ”¹è¿›æœºåˆ¶

### ğŸ¯ é’ˆå¯¹æ€§å»ºè®®

åŸºäºæ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæˆ‘å»ºè®®ï¼š

1. **ğŸ” ç«‹å³è¡ŒåŠ¨é¡¹**
   - è¿›è¡Œæ•°æ®è´¨é‡ç°çŠ¶è¯„ä¼°
   - å»ºç«‹åŸºç¡€æ•°æ®æ ‡å‡†
   - éƒ¨ç½²ç›‘æ§å‘Šè­¦æœºåˆ¶

2. **ğŸ“ˆ ä¸­æœŸå‘å±•é¡¹**  
   - æ„å»ºå…ƒæ•°æ®ç®¡ç†ä½“ç³»
   - å®æ–½æ•°æ®åˆ†ç±»å’Œæ ‡ç­¾
   - å»ºç«‹æ•°æ®æ²»ç†å§”å‘˜ä¼š

3. **ğŸš€ é•¿æœŸæˆ˜ç•¥é¡¹**
   - AIé©±åŠ¨çš„æ™ºèƒ½æ²»ç†
   - è‡ªåŠ¨åŒ–æ•°æ®è¿è¥
   - æ•°æ®ä»·å€¼é‡åŒ–ä½“ç³»

### ğŸ’¼ é¢„æœŸæ”¶ç›Š
å®æ–½å®Œæ•´çš„æ•°æ®æ²»ç†ä½“ç³»åï¼Œé¢„æœŸå¯ä»¥è·å¾—ï¼š
- ğŸ“Š **æ•°æ®è´¨é‡æå‡**ï¼š60-80%
- âš¡ **å†³ç­–æ•ˆç‡æå‡**ï¼š40-60%  
- ğŸ’° **è¿è¥æˆæœ¬é™ä½**ï¼š30-50%
- ğŸ›¡ï¸ **åˆè§„é£é™©é™ä½**ï¼š70-90%

è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å…·ä½“ä¸šåŠ¡åœºæ™¯å’Œå½“å‰ç—›ç‚¹ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›æ›´åŠ å®šåˆ¶åŒ–çš„å»ºè®®ï¼`,
        `## ğŸ” æ·±åº¦æ•°æ®æ²»ç†åˆ†æ

æ‚¨å¥½ï¼æˆ‘ç†è§£æ‚¨å¯¹æ•°æ®æ²»ç†çš„ä¸“ä¸šéœ€æ±‚ã€‚è®©æˆ‘ä¸ºæ‚¨æä¾›ä¸€ä»½è¯¦ç»†çš„åˆ†æå’Œå»ºè®®ï¼š

### ğŸ“Š æ•°æ®æ²»ç†æˆç†Ÿåº¦è¯„ä¼°

#### ğŸ¯ å½“å‰è¡Œä¸šåŸºå‡†
\`\`\`markdown
## æ•°æ®æ²»ç†æˆç†Ÿåº¦æ¨¡å‹

| æˆç†Ÿåº¦ç­‰çº§ | ç‰¹å¾æè¿° | å…¸å‹è¡¨ç° | æ”¹è¿›é‡ç‚¹ |
|------------|----------|----------|----------|
| **L1: åˆå§‹çº§** | æ— åºç®¡ç† | è¢«åŠ¨å“åº”é—®é¢˜ | å»ºç«‹åŸºç¡€è§„èŒƒ |
| **L2: å¯é‡å¤çº§** | æµç¨‹åŒ–ç®¡ç† | æœ‰æ ‡å‡†æµç¨‹ | æµç¨‹ä¼˜åŒ– |
| **L3: å®šä¹‰çº§** | æ ‡å‡†åŒ–ç®¡ç† | é‡åŒ–æŒ‡æ ‡ç›‘æ§ | å·¥å…·æ”¯æ’‘ |
| **L4: é‡åŒ–çº§** | åº¦é‡åŒ–ç®¡ç† | æŒç»­æ”¹è¿›æœºåˆ¶ | æ™ºèƒ½åŒ– |
| **L5: ä¼˜åŒ–çº§** | åˆ›æ–°åŒ–ç®¡ç† | é¢„æµ‹æ€§æ²»ç† | ä»·å€¼é©±åŠ¨ |
\`\`\`

#### ğŸ“‹ è‡ªè¯„ä¼°æ£€æŸ¥æ¸…å•
**æ•°æ®è´¨é‡ç®¡ç†**
- [x] æ˜¯å¦æœ‰æ˜ç¡®çš„æ•°æ®è´¨é‡æ ‡å‡†ï¼Ÿ
- [ ] æ˜¯å¦å®šæœŸè¿›è¡Œæ•°æ®è´¨é‡è¯„ä¼°ï¼Ÿ
- [ ] æ˜¯å¦æœ‰æ•°æ®è´¨é‡é—®é¢˜è·Ÿè¸ªæœºåˆ¶ï¼Ÿ

**å…ƒæ•°æ®ç®¡ç†**  
- [ ] æ˜¯å¦å»ºç«‹äº†ç»Ÿä¸€çš„å…ƒæ•°æ®å­—å…¸ï¼Ÿ
- [ ] æ˜¯å¦æ”¯æŒæ•°æ®è¡€ç¼˜è¿½è¸ªï¼Ÿ
- [ ] æ˜¯å¦æä¾›å…ƒæ•°æ®æŸ¥è¯¢æœåŠ¡ï¼Ÿ

**æ•°æ®å®‰å…¨æ²»ç†**
- [x] æ˜¯å¦æœ‰æ•°æ®åˆ†ç±»åˆ†çº§åˆ¶åº¦ï¼Ÿ
- [ ] æ˜¯å¦å®æ–½æ•°æ®è®¿é—®æ§åˆ¶ï¼Ÿ
- [ ] æ˜¯å¦æœ‰æ•°æ®è„±æ•æœºåˆ¶ï¼Ÿ

### ğŸ› ï¸ æŠ€æœ¯å®æ–½æ–¹æ¡ˆ

#### ğŸ—ï¸ æ¶æ„è®¾è®¡
\`\`\`mermaid
graph TB
    subgraph "æ•°æ®æ²»ç†å¹³å°æ¶æ„"
        A[ç”¨æˆ·ç•Œé¢å±‚] --> B[åº”ç”¨æœåŠ¡å±‚]
        B --> C[æ•°æ®æœåŠ¡å±‚] 
        C --> D[å­˜å‚¨è®¡ç®—å±‚]
        
        B --> E[æ²»ç†å¼•æ“]
        B --> F[è´¨é‡ç›‘æ§]
        B --> G[å…ƒæ•°æ®ç®¡ç†]
        B --> H[å®‰å…¨ç®¡æ§]
        
        E --> I[è§„åˆ™å¼•æ“]
        E --> J[å·¥ä½œæµå¼•æ“]
        E --> K[é€šçŸ¥å¼•æ“]
    end
\`\`\`

#### ğŸ”§ æ ¸å¿ƒç»„ä»¶è®¾è®¡
##### 1. æ•°æ®è´¨é‡ç®¡ç†æ¨¡å—
\`\`\`python
class DataQualityManager:
    def __init__(self):
        self.quality_rules = QualityRuleRepository()
        self.assessment_engine = AssessmentEngine()
        self.reporting_service = ReportingService()
    
    def assess_data_quality(self, dataset_id):
        """æ•°æ®è´¨é‡è¯„ä¼°"""
        # è·å–è´¨é‡è§„åˆ™
        rules = self.quality_rules.get_rules_by_dataset(dataset_id)
        
        # æ‰§è¡Œè´¨é‡æ£€æŸ¥
        results = []
        for rule in rules:
            result = self.assessment_engine.execute_rule(dataset_id, rule)
            results.append(result)
        
        # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
        report = self.reporting_service.generate_quality_report(
            dataset_id, results
        )
        
        return {
            'dataset_id': dataset_id,
            'overall_score': self._calculate_overall_score(results),
            'rule_results': results,
            'recommendations': self._generate_recommendations(results),
            'report': report
        }
\`\`\`

##### 2. å…ƒæ•°æ®ç®¡ç†æ¨¡å—  
\`\`\`python
class MetadataManager:
    def __init__(self):
        self.metadata_store = MetadataStore()
        self.lineage_tracker = LineageTracker()
        self.search_engine = MetadataSearchEngine()
    
    def register_metadata(self, metadata):
        """æ³¨å†Œå…ƒæ•°æ®"""
        # éªŒè¯å…ƒæ•°æ®æ ¼å¼
        validated_metadata = self._validate_metadata(metadata)
        
        # å­˜å‚¨å…ƒæ•°æ®
        metadata_id = self.metadata_store.save(validated_metadata)
        
        # å»ºç«‹ç´¢å¼•
        self.search_engine.index(metadata_id, validated_metadata)
        
        return metadata_id
    
    def trace_lineage(self, data_entity_id):
        """æ•°æ®è¡€ç¼˜è¿½è¸ª"""
        return self.lineage_tracker.trace_upstream(data_entity_id)
\`\`\`

### ğŸ“ˆ å®æ–½æ•ˆæœé¢„æœŸ

#### ğŸ¯ é‡åŒ–æŒ‡æ ‡
| æŒ‡æ ‡ç±»åˆ« | åŸºçº¿å€¼ | ç›®æ ‡å€¼ | æå‡å¹…åº¦ |
|----------|--------|--------|----------|
| **æ•°æ®è´¨é‡** | 65% | 85% | +30% |
| **æ²»ç†æ•ˆç‡** | 40% | 75% | +87.5% |
| **åˆè§„æ°´å¹³** | 50% | 80% | +60% |
| **ç”¨æˆ·æ»¡æ„åº¦** | 60% | 85% | +41.7% |

#### ğŸ’¼ ä¸šåŠ¡ä»·å€¼
1. **ğŸ“Š å†³ç­–æ”¯æŒ**
   - æ•°æ®å¯ä¿¡åº¦æå‡ 60%
   - æŠ¥è¡¨ç”Ÿæˆæ—¶é—´ç¼©çŸ­ 70%

2. **ğŸ›¡ï¸ é£é™©æ§åˆ¶**  
   - æ•°æ®æ³„éœ²é£é™©é™ä½ 80%
   - åˆè§„æ£€æŸ¥è¦†ç›–ç‡æå‡ 90%

3. **ğŸ’° æˆæœ¬ä¼˜åŒ–**
   - æ•°æ®ç»´æŠ¤æˆæœ¬é™ä½ 45%
   - äººå·¥å¹²é¢„å‡å°‘ 65%

### ğŸš€ è¡ŒåŠ¨è®¡åˆ’

#### ğŸ“… è¿‘æœŸè®¡åˆ’ (1-3ä¸ªæœˆ)
**Week 1-2: éœ€æ±‚è°ƒç ”**
- [ ] ä¸šåŠ¡éƒ¨é—¨è®¿è°ˆ
- [ ] ç°çŠ¶è¯„ä¼°åˆ†æ
- [ ] ç›®æ ‡è®¾å®šç¡®è®¤

**Week 3-6: æ–¹æ¡ˆè®¾è®¡**
- [ ] æŠ€æœ¯æ¶æ„è®¾è®¡
- [ ] å®æ–½è·¯å¾„è§„åˆ’
- [ ] èµ„æºé¢„ç®—è¯„ä¼°

**Week 7-12: è¯•ç‚¹å®æ–½**
- [ ] æ ¸å¿ƒæ¨¡å—å¼€å‘
- [ ] è¯•ç‚¹åœºæ™¯éªŒè¯
- [ ] æ•ˆæœè¯„ä¼°ä¼˜åŒ–

#### ğŸ“‹ ä¸­æœŸè®¡åˆ’ (3-6ä¸ªæœˆ)
- [ ] å…¨é¢æ¨å¹¿å®æ–½
- [ ] ç”¨æˆ·åŸ¹è®­èµ‹èƒ½
- [ ] è¿ç»´ä½“ç³»å»ºç«‹

#### ğŸ¯ é•¿æœŸè®¡åˆ’ (6-12ä¸ªæœˆ)
- [ ] æŒç»­ä¼˜åŒ–æ”¹è¿›
- [ ] æ™ºèƒ½åŒ–å‡çº§
- [ ] ä»·å€¼é‡åŒ–è¯„ä¼°

### ğŸ’¡ å…³é”®æˆåŠŸå› ç´ 

1. **ğŸ‘¥ é«˜å±‚æ”¯æŒ**ï¼šç¡®ä¿è·å¾—è¶³å¤Ÿçš„èµ„æºæŠ•å…¥
2. **ğŸ”„ è·¨éƒ¨é—¨åä½œ**ï¼šå»ºç«‹æœ‰æ•ˆçš„æ²Ÿé€šåä½œæœºåˆ¶  
3. **ğŸ“Š åº¦é‡ä½“ç³»**ï¼šå»ºç«‹ç§‘å­¦çš„æˆæ•ˆè¯„ä¼°æ–¹æ³•
4. **ğŸ“ æŒç»­åŸ¹è®­**ï¼šæå‡å›¢é˜Ÿæ•°æ®æ²»ç†èƒ½åŠ›
5. **ğŸš€ æŠ€æœ¯åˆ›æ–°**ï¼šä¿æŒæŠ€æœ¯å…ˆè¿›æ€§å’Œé€‚ç”¨æ€§

è¯·å‘Šè¯‰æˆ‘æ‚¨æœ€å…³æ³¨çš„æ–¹é¢ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›æ›´åŠ è¯¦ç»†å’Œé’ˆå¯¹æ€§çš„å®æ–½æ–¹æ¡ˆï¼`,
        `## ğŸ‰ æ¬¢è¿ä½¿ç”¨AIæ•°æ®æ²»ç†åŠ©æ‰‹ï¼

å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼æˆ‘æ˜¯æ‚¨çš„ä¸“ä¸šæ•°æ®æ²»ç†ä¼™ä¼´ï¼Œè‡´åŠ›äºå¸®åŠ©æ‚¨è§£å†³å„ç§æ•°æ®æŒ‘æˆ˜ã€‚

### ğŸŒŸ æˆ‘çš„æ ¸å¿ƒä»·å€¼

#### ğŸ’¼ ä¸šåŠ¡ä»·å€¼é©±åŠ¨
\`\`\`markdown
## æ•°æ®æ²»ç†ä¸šåŠ¡ä»·å€¼çŸ©é˜µ
| ä»·å€¼ç»´åº¦ | çŸ­æœŸæ”¶ç›Š | é•¿æœŸæ”¶ç›Š | å®æ–½å¤æ‚åº¦ |
|----------|----------|----------|------------|
| **ğŸ“Š å†³ç­–è´¨é‡** | +25% | +60% | ğŸŸ¡ ä¸­ç­‰ |
| **âš¡ è¿è¥æ•ˆç‡** | +40% | +80% | ğŸŸ¢ ç®€å• |
| **ğŸ›¡ï¸ é£é™©æ§åˆ¶** | +35% | +75% | ğŸŸ¡ ä¸­ç­‰ |
| **ğŸ’° æˆæœ¬ä¼˜åŒ–** | +20% | +50% | ğŸŸ¢ ç®€å• |
| **ğŸš€ åˆ›æ–°èƒ½åŠ›** | +15% | +90% | ğŸ”´ å›°éš¾ |
\`\`\`

#### ğŸ¯ æŠ€æœ¯èƒ½åŠ›è¦†ç›–
- **ğŸ” æ™ºèƒ½åˆ†æ**ï¼šæœºå™¨å­¦ä¹ é©±åŠ¨çš„æ·±åº¦æ•°æ®æ´å¯Ÿ
- **ğŸ—‚ï¸ è‡ªåŠ¨åˆ†ç±»**ï¼šAIèµ‹èƒ½çš„æ™ºèƒ½æ•°æ®åˆ†ç±»å’Œæ ‡ç­¾
- **ğŸ›¡ï¸ è´¨é‡ä¿éšœ**ï¼šå…¨æ–¹ä½çš„æ•°æ®è´¨é‡ç›‘æ§å’Œæ²»ç†
- **ğŸ“ é«˜æ•ˆå¤„ç†**ï¼šå¤šæ ¼å¼æ–‡ä»¶çš„æ™ºèƒ½å¤„ç†å’Œè½¬æ¢

### ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

#### ğŸ“‹ ç¬¬ä¸€æ­¥ï¼šæ˜ç¡®æ‚¨çš„éœ€æ±‚
è¯·å‘Šè¯‰æˆ‘æ‚¨å½“å‰é¢ä¸´çš„å…·ä½“æŒ‘æˆ˜ï¼š

1. **ğŸ“Š æ•°æ®åˆ†æéœ€æ±‚**
   - ä¸šåŠ¡æ•°æ®è¶‹åŠ¿åˆ†æ
   - æ•°æ®è´¨é‡é—®é¢˜è¯†åˆ«
   - ç»Ÿè®¡æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆ

2. **ğŸ—‚ï¸ æ•°æ®æ•´ç†éœ€æ±‚**
   - å¤§é‡æ•°æ®æ™ºèƒ½åˆ†ç±»
   - é‡å¤æ•°æ®å»é‡å¤„ç†
   - æ•°æ®æ ‡å‡†åŒ–å’Œè§„èŒƒåŒ–

3. **ğŸ›¡ï¸ æ²»ç†ç®¡ç†éœ€æ±‚**
   - æ•°æ®è´¨é‡ç›‘æ§ä½“ç³»
   - å…ƒæ•°æ®ç®¡ç†å¹³å°
   - æ•°æ®å®‰å…¨å’Œåˆè§„ç®¡ç†

4. **ğŸ“ æ–‡ä»¶å¤„ç†éœ€æ±‚**
   - å¤šæ ¼å¼æ–‡ä»¶æ‰¹é‡å¤„ç†
   - æ•°æ®æå–å’Œè½¬æ¢
   - å¤§æ–‡ä»¶æ€§èƒ½ä¼˜åŒ–

#### ğŸ”§ ç¬¬äºŒæ­¥ï¼šé€‰æ‹©è§£å†³æ–¹æ¡ˆ
æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä¼šä¸ºæ‚¨å®šåˆ¶æœ€é€‚åˆçš„è§£å†³æ–¹æ¡ˆï¼š

**åœºæ™¯Aï¼šæ•°æ®è´¨é‡æå‡**
\`\`\`python
# æ•°æ®è´¨é‡æå‡æ–¹æ¡ˆ
def improve_data_quality(dataset):
    """æ•°æ®è´¨é‡æå‡æµç¨‹"""
    # 1. è´¨é‡è¯„ä¼°
    quality_report = assess_data_quality(dataset)
    
    # 2. é—®é¢˜è¯†åˆ«
    issues = identify_quality_issues(quality_report)
    
    # 3. æ¸…æ´—å¤„ç†
    cleaned_data = clean_dataset(dataset, issues)
    
    # 4. éªŒè¯ç¡®è®¤
    validation_result = validate_cleaning_result(cleaned_data)
    
    return {
        'original_data': dataset,
        'cleaned_data': cleaned_data,
        'quality_report': quality_report,
        'improvement_metrics': calculate_improvement(dataset, cleaned_data)
    }
\`\`\`

**åœºæ™¯Bï¼šæ™ºèƒ½æ•°æ®åˆ†ç±»**
\`\`\`python
# æ™ºèƒ½æ•°æ®åˆ†ç±»æ–¹æ¡ˆ
def intelligent_data_classification(data, categories):
    """æ™ºèƒ½æ•°æ®åˆ†ç±»æµç¨‹"""
    # 1. ç‰¹å¾æå–
    features = extract_features(data)
    
    # 2. æ¨¡å‹æ¨ç†
    classification_results = classify_with_ml_model(features, categories)
    
    # 3. ç½®ä¿¡åº¦è¯„ä¼°
    confidence_scores = evaluate_confidence(classification_results)
    
    # 4. ç»“æœä¼˜åŒ–
    optimized_results = optimize_classification_results(
        classification_results, confidence_scores
    )
    
    return {
        'original_data': data,
        'classification_results': optimized_results,
        'confidence_scores': confidence_scores,
        'recommendations': generate_classification_recommendations(optimized_results)
    }
\`\`\`

**åœºæ™¯Cï¼šæ–‡ä»¶æ‰¹é‡å¤„ç†**
\`\`\`python
# æ–‡ä»¶æ‰¹é‡å¤„ç†æ–¹æ¡ˆ
def batch_file_processing(file_list, processing_config):
    """æ–‡ä»¶æ‰¹é‡å¤„ç†æµç¨‹"""
    processing_results = []
    
    for file_path in file_list:
        try:
            # 1. æ–‡ä»¶è§£æ
            file_data = parse_file(file_path)
            
            # 2. æ•°æ®å¤„ç†
            processed_data = process_data(file_data, processing_config)
            
            # 3. è´¨é‡æ£€æŸ¥
            quality_check = check_data_quality(processed_data)
            
            # 4. ç»“æœè¾“å‡º
            output_path = save_processed_data(processed_data, file_path)
            
            processing_results.append({
                'file_path': file_path,
                'status': 'success',
                'output_path': output_path,
                'quality_score': quality_check['overall_score'],
                'processing_time': calculate_processing_time(file_path)
            })
            
        except Exception as e:
            processing_results.append({
                'file_path': file_path,
                'status': 'error',
                'error_message': str(e),
                'processing_time': calculate_processing_time(file_path)
            })
    
    return {
        'total_files': len(file_list),
        'successful_files': len([r for r in processing_results if r['status'] == 'success']),
        'failed_files': len([r for r in processing_results if r['status'] == 'error']),
        'success_rate': len([r for r in processing_results if r['status'] == 'success']) / len(file_list),
        'average_processing_time': sum(r['processing_time'] for r in processing_results) / len(processing_results),
        'details': processing_results
    }
\`\`\`

### ğŸ’¡ ä¸“ä¸šå»ºè®®

#### ğŸ¯ æ•°æ®æ²»ç†æœ€ä½³å®è·µ
1. **ğŸ“‹ åˆ¶å®šæ ‡å‡†**
   - å»ºç«‹ä¼ä¸šçº§æ•°æ®æ ‡å‡†è§„èŒƒ
   - ç»Ÿä¸€æ•°æ®å®šä¹‰å’Œæ ¼å¼è¦æ±‚
   - åˆ¶å®šæ•°æ®è´¨é‡ç®¡ç†æµç¨‹

2. **ğŸ”§ å·¥å…·æ”¯æ’‘**
   - éƒ¨ç½²ä¸“ä¸šæ•°æ®æ²»ç†å·¥å…·å¹³å°
   - å»ºç«‹è‡ªåŠ¨åŒ–ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶
   - å®æ–½å…ƒæ•°æ®ç®¡ç†ç³»ç»Ÿ

3. **ğŸ‘¥ ç»„ç»‡ä¿éšœ**
   - æˆç«‹æ•°æ®æ²»ç†å§”å‘˜ä¼š
   - æ˜ç¡®æ•°æ®è´£ä»»äººåˆ¶åº¦
   - å»ºç«‹æ•°æ®æ²»ç†ç»©æ•ˆè€ƒæ ¸

4. **ğŸ“Š æŒç»­æ”¹è¿›**
   - å®šæœŸè¯„ä¼°æ²»ç†æ•ˆæœ
   - æ”¶é›†ç”¨æˆ·åé¦ˆæ„è§
   - ä¼˜åŒ–æ²»ç†æµç¨‹å’Œå·¥å…·

#### ğŸš€ å®æ–½è·¯å¾„å»ºè®®
**çŸ­æœŸç›®æ ‡ (1-3ä¸ªæœˆ)**
- å®Œæˆæ•°æ®æ²»ç†ç°çŠ¶è¯„ä¼°
- å»ºç«‹åŸºç¡€æ•°æ®è´¨é‡ç›‘æ§
- å®æ–½å…³é”®æ•°æ®åˆ†ç±»é¡¹ç›®

**ä¸­æœŸç›®æ ‡ (3-6ä¸ªæœˆ)**
- éƒ¨ç½²å…ƒæ•°æ®ç®¡ç†å¹³å°
- å»ºç«‹æ•°æ®å®‰å…¨ç®¡æ§æœºåˆ¶
- å¼€å±•æ•°æ®æ²»ç†åŸ¹è®­æ¨å¹¿

**é•¿æœŸç›®æ ‡ (6-12ä¸ªæœˆ)**
- å®ç°æ™ºèƒ½åŒ–æ•°æ®æ²»ç†
- å»ºç«‹æ•°æ®ä»·å€¼è¯„ä¼°ä½“ç³»
- å½¢æˆæŒç»­æ”¹è¿›æœºåˆ¶

### ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

ä¸ºäº†æ›´å¥½åœ°ä¸ºæ‚¨æä¾›ç²¾å‡†æœåŠ¡ï¼Œå»ºè®®æ‚¨ï¼š

1. **ğŸ“ æè¿°å…·ä½“éœ€æ±‚**
   - æ‚¨å½“å‰é¢ä¸´çš„ä¸»è¦æ•°æ®æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ
   - å¸Œæœ›è§£å†³å“ªäº›å…·ä½“é—®é¢˜ï¼Ÿ
   - æœ‰ä»€ä¹ˆç‰¹å®šçš„ä¸šåŠ¡ç›®æ ‡ï¼Ÿ

2. **ğŸ“Š æä¾›èƒŒæ™¯ä¿¡æ¯**
   - å½“å‰æ•°æ®è§„æ¨¡å’Œç±»å‹
   - ç°æœ‰æŠ€æœ¯æ¶æ„å’Œå·¥å…·
   - å›¢é˜ŸæŠ€æœ¯èƒ½åŠ›å’Œç»éªŒ

3. **ğŸ¯ è®¾å®šæœŸæœ›ç›®æ ‡**
   - å¸Œæœ›è¾¾åˆ°ä»€ä¹ˆæ ·çš„æ•ˆæœï¼Ÿ
   - æœ‰ä»€ä¹ˆæ—¶é—´èŠ‚ç‚¹è¦æ±‚ï¼Ÿ
   - é¢„ç®—å’Œèµ„æºæŠ•å…¥æƒ…å†µï¼Ÿ

æœ‰äº†è¿™äº›ä¿¡æ¯ï¼Œæˆ‘å°±èƒ½ä¸ºæ‚¨é‡èº«å®šåˆ¶æœ€é€‚åˆçš„è§£å†³æ–¹æ¡ˆï¼

è¯·éšæ—¶å‘Šè¯‰æˆ‘æ‚¨çš„æƒ³æ³•ï¼Œæˆ‘å·²ç»å‡†å¤‡å¥½ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æ•°æ®æ²»ç†æœåŠ¡ï¼ğŸš€`,
      ],
    };

    // æ ¹æ®è¾“å…¥å†…å®¹é€‰æ‹©åˆé€‚çš„å›å¤
    if (
      lowerInput.includes('ä½ å¥½') ||
      lowerInput.includes('hi') ||
      lowerInput.includes('hello')
    ) {
      return responses.greeting[
        Math.floor(Math.random() * responses.greeting.length)
      ];
    }

    if (lowerInput.includes('æ•°æ®') && lowerInput.includes('åˆ†æ')) {
      return responses.dataAnalysis[
        Math.floor(Math.random() * responses.dataAnalysis.length)
      ];
    }

    if (lowerInput.includes('æ–‡ä»¶') || lowerInput.includes('ä¸Šä¼ ') || file) {
      return responses.fileProcessing[
        Math.floor(Math.random() * responses.fileProcessing.length)
      ];
    }

    if (
      lowerInput.includes('å¸®åŠ©') ||
      lowerInput.includes('æ€ä¹ˆ') ||
      lowerInput.includes('å¦‚ä½•')
    ) {
      return responses.help[Math.floor(Math.random() * responses.help.length)];
    }

    // é»˜è®¤å›å¤
    return responses.default[
      Math.floor(Math.random() * responses.default.length)
    ];
  };

  const handleSubmit = async () => {
    if (!inputText.trim() || isLoading) return;

    // ä¿å­˜å½“å‰æ–‡ä»¶ä¿¡æ¯ï¼Œç”¨äºAIå›å¤
    const currentFile = uploadedFile;

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    const userMessage = {
      id: Date.now(),
      type: 'text',
      content: inputText,
      sender: 'user' as const,
      timestamp: new Date(),
    };
    setMessages((prev) => [...prev, userMessage]);

    const currentInput = inputText;
    setInputText('');
    setError(null);
    setIsLoading(true);

    // å‘é€æ¶ˆæ¯åæ¸…ç©ºæ–‡ä»¶æ¡†
    setUploadedFile(null);

    try {
      // ç”Ÿæˆæ¨¡æ‹Ÿå›å¤å†…å®¹
      const mockResponse = generateMockResponse(currentInput, currentFile);

      // åˆ›å»ºAIæ¶ˆæ¯å ä½ç¬¦
      const aiMessageId = Date.now() + 1;
      const aiMessage = {
        id: aiMessageId,
        type: 'text' as const,
        content: '',
        sender: 'ai' as const,
        timestamp: new Date(),
      };
      setMessages((prev) => [...prev, aiMessage]);

      // æ¨¡æ‹Ÿæµå¼æ˜¾ç¤ºæ•ˆæœ
      let fullContent = '';
      for (let i = 0; i < mockResponse.length; i++) {
        // æ·»åŠ å°å»¶è¿Ÿæ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
        await new Promise((resolve) => setTimeout(resolve, 5));
        fullContent += mockResponse[i];
        setMessages((prev) =>
          prev.map((msg) =>
            msg.id === aiMessageId ? { ...msg, content: fullContent } : msg
          )
        );
      }
    } catch (error) {
      console.error('æ¨¡æ‹Ÿå¯¹è¯é”™è¯¯:', error);
      const errorMessage =
        error instanceof Error
          ? error.message
          : 'æ¨¡æ‹Ÿå¯¹è¯æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•';
      setError(errorMessage);

      // æ·»åŠ é”™è¯¯æ¶ˆæ¯
      const errorMessageObj = {
        id: Date.now() + 1,
        type: 'text' as const,
        content: `æŠ±æ­‰ï¼Œå‡ºç°äº†é”™è¯¯: ${errorMessage}`,
        sender: 'ai' as const,
        timestamp: new Date(),
      };
      setMessages((prev) => [...prev, errorMessageObj]);
    } finally {
      setIsLoading(false);
    }
  };

  // æ ¼å¼åŒ–æ—¶é—´
  const formatTime = (date: Date) => {
    return date.toLocaleTimeString('zh-CN', {
      hour: '2-digit',
      minute: '2-digit',
    });
  };

  return (
    <div
      className={`flex-1 flex flex-col mb-6 ${
        messages.length === 0 ? '' : 'h-dvh overflow-y-hidden'
      }`}
    >
      {/* åœ¨æ²¡æœ‰å‘ç”Ÿå¯¹è¯çš„æ—¶å€™æ˜¾ç¤ºCanvasèƒŒæ™¯ */}
      {messages.length === 0 && (
        <CanvasBackground gridSize={25} animationSpeed={0.18} />
      )}

      {/* å¯¹è¯é¡µé¢çš„è’™ç‰ˆ */}
      {messages.length == 0 && (
        <div
          className="absolute bottom-0 left-0 right-0 pointer-events-none"
          style={{
            zIndex: 0,
            opacity: 1,
            backgroundImage:
              'linear-gradient(to top, rgba(255,255,255,0.7), transparent)',
            backgroundSize: '100% 35vh',
            backgroundPosition: 'bottom',
            backgroundRepeat: 'no-repeat',
            height: '35vh',
          }}
        />
      )}

      {messages.length == 0 && (
        <div
          className="absolute top-0 left-0 right-0 pointer-events-none"
          style={{
            zIndex: 0,
            opacity: 1,
            backgroundImage:
              'linear-gradient(to bottom, rgba(255,255,255,0.7), transparent)',
            backgroundSize: '100% 35vh',
            backgroundPosition: 'top',
            backgroundRepeat: 'no-repeat',
            height: '35vh',
          }}
        />
      )}

      {/* å¯¹è¯å†…å®¹åŒºåŸŸ */}
      <div
        ref={contentRef}
        className={`${
          messages.length === 0 ? 'hidden' : 'flex-1 overflow-y-auto'
        }`}
      >
        <div className="container mx-auto py-4 px-4">
          {/* å¯¹è¯æ¶ˆæ¯ */}
          {messages.map((message) => (
            <div
              key={message.id}
              className={`mb-4 flex ${
                message.sender === 'user' ? 'justify-end' : 'justify-start'
              }`}
            >
              <div
                className={`max-w-3xl px-4 py-3 ${
                  message.sender === 'user'
                    ? 'rounded-[var(--s-radius-s)] bg-[rgba(0,0,0,0.04)] text-[var(--s-color-text-primary)]'
                    : 'text-[var(--s-color-text-primary)]'
                }`}
              >
                <div className="flex items-start gap-4">
                  <div className="flex-1">
                    {message.type === 'file' && message.file && (
                      <div className="flex items-center gap-2 mb-2">
                        <FileText className="w-4 h-4 text-[var(--s-color-text-secondary)]" />
                        <span className="text-sm font-medium text-[var(--s-color-text-primary)]">
                          {message.file.name}
                        </span>
                      </div>
                    )}
                    <div className="flex flex-col gap-4 text-[rgba(0,0,0,0.85)]">
                      <Markdown>{message.content}</Markdown>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          ))}
        </div>
      </div>

      {/* é—®å€™è¯­ - åªåœ¨æ²¡æœ‰æ¶ˆæ¯æ—¶æ˜¾ç¤º */}
      {messages.length === 0 && (
        <div className="text-center mb-12">
          <h1 className="text-3xl font-semibold text-center text-gray-800">
            ä½ å¥½ï¼Œæˆ‘æ˜¯AIæ•°æ®æ²»ç†åŠ©æ‰‹ï¼
          </h1>
        </div>
      )}

      {/* åº•éƒ¨è¾“å…¥åŒºåŸŸ */}
      <section
        ref={inputRef}
        className={`w-full flex justify-center pb-4 mb-4 pt-4 z-100 ${
          messages.length === 0 ? 'mt-auto' : 'bg-background mt-auto'
        }`}
      >
        <div className="flex bg-white justify-center w-188 z-[90] border border-neutral-200/50 dark:border-white/15 rounded-2xl transition-all duration-200 hover:border-neutral-300 dark:hover:border-neutral-700">
          <div className="relative">
            <Textarea
              placeholder="å‘æ¶ˆæ¯ï¼Œå¼€å§‹ä½ çš„æ•°æ®æ²»ç†ä¹‹è·¯..."
              rows={2}
              maxRows={5}
              tabIndex={0}
              spellCheck={false}
              value={inputText}
              autoFocus
              onChange={(e) => setInputText(e.target.value)}
              onKeyDown={(e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                  e.preventDefault();
                  handleSubmit();
                }
              }}
              className={`mark-scroll-bar w-185 flex-1 input-color font-geist-mono resize-none min-w-xl border-0 p-2 text-sm min-h-24 placeholder:text-muted-foreground focus-visible:outline-none disabled:cursor-not-allowed disabled:opacity-50`}
            />

            {/* å·¦ä¸‹è§’æ§åˆ¶åŒºåŸŸ */}
            <div className="mt-auto ml-2 mb-2 flex items-center gap-3">
              {uploadedFile ? (
                <div className="flex items-center gap-2 p-2 border rounded-md bg-gray-50">
                  <FileText className="w-4 h-4 text-gray-600" />
                  <span className="text-sm text-gray-700">
                    {uploadedFile.name}
                  </span>
                  <Button
                    variant="ghost"
                    size="icon"
                    onClick={handleClearFile}
                    className="w-4 h-4"
                  >
                    <X className="w-3 h-3" />
                  </Button>
                </div>
              ) : (
                <FileUpload onFileUpload={handleFileUpload} />
              )}
            </div>

            {/* å³ä¸‹è§’å‘é€æŒ‰é’® */}
            <div>
              <button
                onClick={handleSubmit}
                className={`absolute bottom-3 right-3 size-8 flex justify-center items-center transition-all duration-200 rounded-full ${
                  inputText.trim() && !isLoading
                    ? 'bg-blue-500 cursor-pointer hover:bg-blue-600'
                    : 'bg-gray-300 cursor-not-allowed'
                }`}
                disabled={!inputText.trim() || isLoading}
              >
                {isLoading ? (
                  <Loader2
                    size={18}
                    className="text-white font-semibold animate-spin"
                  />
                ) : (
                  <ArrowUp size={18} className={`text-white font-semibold`} />
                )}
              </button>
            </div>
          </div>
        </div>
      </section>
    </div>
  );
}
